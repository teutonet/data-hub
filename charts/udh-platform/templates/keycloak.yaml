---
apiVersion: source.toolkit.fluxcd.io/v1
kind: HelmRepository
metadata:
  name: {{ include "data-hub.name" (dict "context" . "name" "bitnami") }}
spec:
  interval: 1h0m0s
  url: https://charts.bitnami.com/bitnami
---
apiVersion: helm.toolkit.fluxcd.io/v2
kind: HelmRelease
metadata:
  name: {{ include "data-hub.name" (dict "context" . "name" "keycloak") }}
spec:
  releaseName: {{ include "data-hub.name" (dict "context" . "name" "sso") }}
  chart:
    spec:
      chart: keycloak
      version: 18.3.4
      reconcileStrategy: ChartVersion
      sourceRef:
        kind: HelmRepository
        name: {{ include "data-hub.name" (dict "context" . "name" "bitnami") }}
  interval: 1h0m0s
  timeout: 10m
  targetNamespace: {{ .Release.Namespace }}
  dependsOn:
    - name: {{ include "data-hub.name" (dict "context" . "name" "grafana") }}
  values:
    postgresql:
      enabled: false
    replicaCount: {{ .Values.keycloak.replicaCount }}
    externalDatabase:
      host: {{ printf "%s-postgres" (include "common.names.fullname" .) }}
      port: 5432
      database: keycloak
      existingSecret: {{ printf "keycloak-owner-user.%s-postgres.credentials.postgresql.acid.zalan.do" (include "common.names.fullname" .) | quote }}
      existingSecretUserKey: "username"
      existingSecretPasswordKey: "password"
    extraStartupArgs: --features=admin-fine-grained-authz
    production: true
    # The keycloak chart expects a list of strings, not a map
    {{- $imagePullSecrets := get (include "udh-platform.imagePullSecrets" (dict "context" .) | fromYaml) "imagePullSecrets" }}
    {{- if $imagePullSecrets }}
    global:
      imagePullSecrets:
      {{- range $entry := $imagePullSecrets }}
        - {{ get $entry "name" }}
      {{- end }}
    {{- end }}
    service:
      type: ClusterIP
      http:
        enabled: false
    resources: {{- $.Values.keycloak.resources | toYaml | nindent 6 }}
    ingress:
      enabled: true
      hostname: {{ include "data-hub.keycloak.hostname" . }}
      tls: true
      servicePort: https
      annotations: {{- include "udh.ingress.annotations" (dict "context" $ "annotations" .Values.keycloak.ingress.annotations) | nindent 8 }}
        nginx.ingress.kubernetes.io/proxy-buffer-size: "64k"
        nginx.ingress.kubernetes.io/backend-protocol: "HTTPS"
        nginx.ingress.kubernetes.io/enable-cors: "true"
        nginx.ingress.kubernetes.io/cors-allow-origin: "https://{{ (include "sensor-ingestion.mdb.frontend.hostname" .) }}"
    tls:
      enabled: true
      autoGenerated: true
    extraVolumes:
      - name: extensions
        emptyDir:
          sizeLimit: 100Mi
    extraVolumeMounts:
      - mountPath: /opt/bitnami/keycloak/providers/
        name: extensions
    initContainers:
      - name: extensions
        image: {{ include "udh-platform.images.keycloak.extensions" (dict "context" .) }}
        imagePullPolicy: {{ .Values.keycloak.extensions.image.pullPolicy }}
        volumeMounts:
          - mountPath: /target
            name: extensions
    extraEnvVars:
      - name: KEYCLOAK_ENABLE_HEALTH_ENDPOINTS
        value: "true"
      - name: PROMETHEUS_HOST
        value: {{ include "data-hub.name" (dict "context" . "name" "mimir-nginx") }}
      - name: GRAFANA_HOST
        value: {{ include "data-hub.name" (dict "context" . "name" "grafana") }}
      - name: GRAFANA_USER
        valueFrom:
          secretKeyRef:
            name: {{ include "data-hub.name" (dict "context" . "name" "grafana") }}
            key: admin-user
      - name: GRAFANA_PASSWORD
        valueFrom:
          secretKeyRef:
            name: {{ include "data-hub.name" (dict "context" . "name" "grafana") }}
            key: admin-password
      {{- if .Values.objectStorage.enabled }}
      - name: BUCKET_ENDPOINT
        value: {{ print "storage." .Values.global.baseDomain | quote }}
      - name: AWS_ACCESS_KEY_ID
        valueFrom:
          secretKeyRef:
            name: {{ printf "rook-ceph-object-user-bucket-%s-bucket-admin" (include "common.names.fullname" .) | quote }}
            key: AccessKey
      - name: AWS_SECRET_ACCESS_KEY
        valueFrom:
          secretKeyRef:
            name: {{ printf "rook-ceph-object-user-bucket-%s-bucket-admin" (include "common.names.fullname" .) | quote }}
            key: SecretKey
      {{- end }}
    keycloakConfigCli:
      enabled: true
      configuration:
        {{ .Values.keycloak.realm }}.yaml: |
          realm: {{ .Values.keycloak.realm }}

          # TODO delete workaround once https://github.com/ceph/ceph/pull/53915 has landed in our clusters
          # more info https://tracker.ceph.com/issues/54562
          components:
            org.keycloak.keys.KeyProvider:
            - name: rsa-generated
              providerId: rsa-generated
              config:
                priority:
                - '150'
          loginTheme: teuto-data-hub
          internationalizationEnabled: true
          supportedLocales:
            - de
          defaultLocale: de
          {{- if .Values.keycloak.smtp }}
          smtpServer:
            from: {{ printf "keycloak-%s" .Values.global.smtp_base_domain | quote}}
            fromDisplayName: {{ .Values.keycloak.smtp.fromDisplayName | quote}}
            {{- if .Values.mailhog.enabled }}
            host: {{ printf "%s-mailhog" .Release.Name | quote }}
            {{- else }}
            host: {{ .Values.keycloak.smtp.host | quote}}
            {{- end }}
            port: {{ .Values.keycloak.smtp.port }}
            auth: {{ .Values.keycloak.smtp.auth }}
            ssl: {{ .Values.keycloak.smtp.ssl }}
            envelopeFrom: {{ printf "keycloak-%s" .Values.global.smtp_base_domain | quote}}
            user: {{ .Values.keycloak.smtp.user | quote}}
            password: {{ .Values.keycloak.smtp.password | quote}}
          {{ end -}}
          enabled: true
          loginWithEmailAllowed: true
          rememberMe: true
          bruteForceProtected: true
          internationalizationEnabled: true
          supportedLocales:
            - de
            - en
          defaultLocale: de

          eventsListeners:
            - jboss-logging
            - udh-sync

          clients:
            - clientId: grafana
              publicClient: true
              redirectUris:
                - https://{{ include "data-hub.grafana.hostname" . }}/oauth2/callback
              webOrigins:
                - +
              protocolMappers:
                - name: audience
                  protocol: openid-connect
                  protocolMapper: oidc-audience-mapper
                  config:
                    included.client.audience: grafana
                    included.custom.audience: grafana
                    access.token.claim: 'true'
                - &udh_sync
                  name: udh-sync
                  protocol: openid-connect
                  protocolMapper: udh-sync
                  config:
                    userinfo.token.claim: 'true'
                    id.token.claim: 'true'
                    access.token.claim: 'true'
            - clientId: jupyterhub
              publicClient: true
              defaultClientScopes: []
              optionalClientScopes: [email, profile]
              redirectUris:
                - https://{{ include "data-hub.jupyterhub.hostname" . }}/hub/oauth_callback
              webOrigins:
                - +
            - clientId: usercode
              standardFlowEnabled: false
              defaultClientScopes: []
              attributes:
                oauth2.device.authorization.grant.enabled: 'true'
              publicClient: true
              optionalClientScopes: [prometheus_read, buckets, data-hub]
              protocolMappers:
                - *udh_sync
            - &mdb
              clientId: mdb
              redirectUris:
                - https://mdb.{{ .Values.global.baseDomain }}/oauth2/callback
              webOrigins:
                - +
              publicClient: true
              defaultClientScopes: []
              optionalClientScopes: []
              attributes:
                access.token.lifespan: 300
              protocolMappers:
                - name: audience-mdb
                  protocol: openid-connect
                  protocolMapper: oidc-audience-mapper
                  config:
                    included.custom.audience: mdb
                    access.token.claim: "true"
                - *udh_sync
            - <<: *mdb
              clientId: mdb-frontend
              baseUrl: https://mdb-frontend.{{ .Values.global.baseDomain }}
              redirectUris:
                - https://mdb-frontend.{{ .Values.global.baseDomain }}/auth/
                - https://mdb-frontend.{{ .Values.global.baseDomain }}/auth/silent/
              optionalClientScopes: [profile, data-hub]
            - clientId: data-hub
              standardFlowEnabled: false
              serviceAccountsEnabled: true
              authorizationServicesEnabled: true
              defaultClientScopes: []
              publicClient: false
              optionalClientScopes: []
          clientScopes:
            - name: prometheus_read
              protocol: openid-connect
              attributes:
                display.on.consent.screen: 'true'
                consent.screen.text: Prometheus API (read)
              protocolMappers:
                - name: audience
                  protocol: openid-connect
                  protocolMapper: oidc-audience-mapper
                  config:
                    included.custom.audience: prometheus_read
                    access.token.claim: 'true'
                    id.token.claim: 'true'
            - name: buckets
              protocol: openid-connect
              attributes:
                display.on.consent.screen: 'true'
                consent.screen.text: Object Storage
              protocolMappers:
                - name: audience
                  protocol: openid-connect
                  protocolMapper: oidc-audience-mapper
                  config:
                    included.custom.audience: buckets
                    id.token.claim: 'true'
            - name: data-hub
              protocol: openid-connect
              attributes:
                display.on.consent.screen: 'true'
                consent.screen.text: Resource Management
              protocolMappers:
                - name: audience
                  protocol: openid-connect
                  protocolMapper: oidc-audience-mapper
                  config:
                    included.custom.audience: data-hub
                    access.token.claim: 'true'

          users:
            {{- if $.Values.keycloak.testUsers }}
            {{- range $user := $.Values.keycloak.testUsers }}
            - username: {{ $user.username | default $user.email | quote }}
              {{- if $user.firstName }}
              firstName: {{ $user.firstName }}
              {{- end }}
              {{- if $user.lastName }}
              lastName: {{ $user.lastName }}
              {{- end }}
              email: {{ $user.email | quote }}
              enabled: True
              emailVerified: True
              realmRoles: {{- $user.realmRoles | default (list) | toYaml | nindent 16 }}
              clientRoles: {{- $user.clientRoles | default (dict) | toYaml | nindent 16 }}
              credentials:
                - type: password
                  value: {{ $user.password | quote }}
            {{- end }}
            {{- end }}

          {{ define "udh.keycloak.bruteforce" -}}
          # security defenses / brute force detection
          bruteForceProtected: true
          permanentLockout: false
          failureFactor: 30
          waitIncrementSeconds: 60
          quickLoginCheckMilliSeconds: 1000
          minimumQuickLoginWaitSeconds: 60
          maxFailureWaitSeconds: 900
          maxDeltaTimeSeconds: 43200
          {{- end -}}
          {{ include "udh.keycloak.bruteforce" . }}
        master.yaml: |
          realm: master
          {{ include "udh.keycloak.bruteforce" . }}
